---
title: Modules
description: |
  Week learning objectives, slides, and task list
output:
  distill::distill_article:
    toc: false
---

```{r convert-xaringan, include = FALSE}
# Convert Rmd slides to HTML and PDF
for (f in dir("slides", pattern = "*.Rmd", full.names = TRUE)) {
  html_file <- xfun::with_ext(f, "html")
  pdf_file <- xfun::with_ext(f, "pdf")
  if (!file.exists(html_file) || file_test("-ot", html_file, f)) {
    xfun::Rscript_call(rmarkdown::render, args = list(input = f))
  }
  if (!file.exists(pdf_file) || file_test("-ot", pdf_file, f)) {
    pagedown::chrome_print(html_file)
  }
}
```

```{r add_youtube, include = FALSE}
add_youtube <- function(src) {
    yt_url <- paste0("https://www.youtube.com/embed/", src)
    htmltools::div(
        style = "position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;",
        htmltools::tags$iframe(
            src = yt_url,
            style = "position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;",
            title = "YouTube Video",
            allowfullscreen = ""
        )
    )
}
```

```{r, include = FALSE}
library(xaringanExtra, include.only = "embed_xaringan")
```

```{r panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

::: {.panelset}
::: {.panel}

# Week 1

## Week Learning Objectives

By the end of this module, you will be able to 

- Navigate the course website and Blackboard site
- Identify the Slack channels relevant for the course
- Describe the historical origin of Bayesian statistics
- Identify components in research papers involving Bayesian analyses
- Knit a simple R Markdown file

## Task Lists

1. Review the [syllabus](syllabus.html)
2. Review the resources (slides and [note][5])
3. Install/Update R and RStudio on your computer
4. Attend the Tuesday and Thursday class meetings
5. Complete the assigned readings
    * [Kruschke ch. 2][2]
    * Supplemental (i.e., optional) reading: [James ch. 1][3]
    * [Markdown Quick Reference][4]
6. Introduce yourself on the #introduction Slack channel (as part of HW 1)
7. Complete Homework 1 (see instruction on Blackboard)

[2]: https://drive.google.com/file/d/1tr7XpIVf04S44o5ZploxJcd37Fg1GygV/view
[3]: https://jim-stone.staff.shef.ac.uk/BookBayes2012/bookbayesch01.pdf
[4]: https://web.mit.edu/r/current/RStudio/resources/markdown_help.html
[5]: r_markdown.html

## Slides

[PDF version](slides/intro.pdf){target="_blank"}

```{r embed-1, echo = FALSE}
embed_xaringan("slides/intro.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 2

## Week Learning Objectives

By the end of this module, you will be able to 

- Explain the **three axioms/properties** of probability
- Describe the **subjectivist** interpretation of probability, and contrast it with the **frequentist** interpretation
- Explain the difference between **probability mass** and **probability density**
- Compute probability density using **simulations**
- Compute **joint, marginal, and conditional probabilities** with two variables
- Write an R function and use loops for repeating computations

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 4
    * Wickham & Grolemund ch. [7][6], [19.1-19.5][7]
2. Review the resources (slides and notes on [probability][8] and [R basics][9])
3. Attend the Tuesday and Thursday class meetings
4. Complete Homework 2 (see instruction on Blackboard)

[6]: https://r4ds.had.co.nz/exploratory-data-analysis.html
[7]: https://r4ds.had.co.nz/functions.html
[8]: probability.html
[9]: r_basics.html

## Slides

[PDF version](slides/probability.pdf){target="_blank"}

```{r embed-2, echo = FALSE}
embed_xaringan("slides/probability.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 3

## Week Learning Objectives

By the end of this module, you will be able to 

- Derive **Bayes' rule** from the definition of conditional probability
- Apply Bayes' rule to obtain **posterior** from prior and data
- Explain what **data-order invariance** and **exchangeability** are
- Use **grid approximation** to obtain the posterior for a **Bernoulli** model
- Describe the influence of **sample size** and **prior** on the posterior
- Use R to perform **prior predictive checks**

## Task Lists

1. Complete the assigned readings
    * [Gigerenzer (2004)][1]
    * Kruschke ch. 5
2. Review the resources (slides and [note][10])
3. Attend the Tuesday and Thursday class meetings
4. No homework for this week, but you may work on Q1 and Q2 for Homework 3 (see instruction on Blackboard)

[1]: https://pure.mpg.de/rest/items/item_2101336/component/file_2101335/content
[10]: bayes_rule.html

## Slides

[PDF version](slides/bayes_rule.pdf){target="_blank"}

```{r embed-3, echo = FALSE}
embed_xaringan("slides/bayes_rule.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 4

## Week Learning Objectives

By the end of this module, you will be able to 

- Apply **Bayesian workflow** to analyze real data with a **Bernoulli** model
- Explain the idea of a **conjugate prior**
- Summarize the posterior distribution using **simulations**
- Apply Bayesian **terminology** in summarizing the posterior
- Use R to perform **posterior predictive checks**

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 6
    * [Gabry et al. (2019)][11] for an example of posterior predictive checks
2. Review the resources (slides and [note][12])
    * If interested, check out the [bonus note on the Poisson model][13]
3. Attend the Tuesday and Thursday class meetings
4. Complete Homework 3 (see instruction on Blackboard)

[11]: https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssa.12378
[12]: beta_Bernoulli_model.html
[13]: Poisson_model.html

## Slides

[PDF version](slides/one_parameter_models.pdf){target="_blank"}

```{r embed-4, echo = FALSE}
embed_xaringan("slides/one_parameter_models.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 5

## Week Learning Objectives

By the end of this module, you will be able to 

- Explain *what* is unique for samples using **Markov Chain Monte Carlo (MCMC)**
- Explain *why* we need MCMC to **approximate the posterior**
- Describe *when* MCMC samples are **representative** and **accurate** for approximating the posterior
- Use R to perform **convergence diagnostics** for MCMC samples

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 7
2. Review the resources (slides and [note][14])
3. Attend the Tuesday and Thursday class meetings
4. Complete Homework 4 (see instruction on Blackboard)

[14]: mcmc.html

## Slides

[PDF version](slides/mcmc.pdf){target="_blank"}

```{r embed-5, echo = FALSE}
embed_xaringan("slides/mcmc.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 6

## Week Learning Objectives

By the end of this module, you will be able to 

- Apply **Gibbs sampling** to summarize parameters of a **normal model**
<!--
- Describe, conceptually, how the **Hamiltonian Monte Carlo (HMC)** algorithm achieves a better efficiency with the use of the gradients
- Explain how tuning the **step size** and the **tree depth** affects HMC
- Program a simple Bayesian model in **STAN**
-->

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 7
2. Review the resources (slides and [note][15])
3. Attend the Tuesday and Thursday class meetings
4. Complete Homework 5 (see instruction on Blackboard)

[15]: gibbs.html

## Slides

[PDF version](slides/gibbs.pdf){target="_blank"}

```{r embed-6, echo = FALSE}
embed_xaringan("slides/gibbs.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 7

## Week Learning Objectives

By the end of this module, you will be able to 

- Describe, conceptually, how the **Hamiltonian Monte Carlo (HMC)** algorithm achieves a better efficiency with the use of the gradients
- Explain how tuning the **step size** and the **tree depth** affects HMC
- Program a simple Bayesian model in **Stan**

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 14
2. Review the resources (slides and [note][16])
3. Attend the Tuesday and Thursday class meetings

[16]: hmc_stan.html

## Slides

[PDF version](slides/hmc_stan.pdf){target="_blank"}

```{r embed-7, echo = FALSE}
embed_xaringan("slides/hmc_stan.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 8

## Week Learning Objectives

By the end of this module, you will be able to 

- Explain the logic of a **hierarchical model**
- Apply the **binomial distribution** to describe the sum of multiple Bernoulli trials
- Program a hierarchical binomial model in Stan
- Analyze secondary data using a hierarchical normal model (i.e., random-effect meta-analysis)

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 9
2. Review the resources (slides and [note][17])
3. Attend the Tuesday and Thursday class meetings
4. Start thinking about the class project
    * Prospectus due March 21

[17]: hierarchical_models.html

## Slides

[PDF version](slides/hierarchical_models.pdf){target="_blank"}

```{r embed-8, echo = FALSE}
embed_xaringan("slides/hierarchical_models.html", ratio = "4:3")
```

## Lecture Videos

### Hierarchical binomial

```{r, echo = FALSE}
add_youtube("GJcs8utKhBQ")
```

```{r, echo = FALSE}
add_youtube("GCpRvcrqQ9E")
```

### Hierarchical normal

```{r, echo = FALSE}
add_youtube("GmB2rs-W1eE")
```

```{r, echo = FALSE}
add_youtube("OC9oH5GRErU")
```

```{r, echo = FALSE}
add_youtube("yQExiCLVcCk")
```

:::

::: {.panel}

# Week 9

## Week Learning Objectives

By the end of this module, you will be able to 

- Conduct a Bayesian **comparison** of two groups
- Apply a **$t$ model** for robust modeling
- Select an appropriate distribution for different kinds of data
- Conduct comparisons with hierarchical data (e.g., within-subject designs)

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 12.1, 16
2. Review the resources ([note][18])
3. Attend class meetings
4. Start thinking about the class project
    * Prospectus due March 21

[18]: group_comparisons.html

:::

::: {.panel}

# Week 11

## Week Learning Objectives

By the end of this module, you will be able to 

- Describe the three components of the **generalized linear model (GLM)**
- Name examples of the GLM (e.g., linear regression, Poisson regression)
- Interpret the coefficients in a linear regression model
- Obtain posterior predictive distributions and checks
- Perform Bayesian regression with the R package `brms`

## Task Lists

1. Complete the assigned readings
    * Kruschke ch. 15, 17
2. Review the resources ([note][19])
3. Attend class meetings
4. Complete Homework 7 (see instruction on Blackboard)
5. Schedule a meeting with the instructor for your prospectus (see sign-up link on Blackboard)

[19]: glm.html

## Slides

[PDF version](slides/glm.pdf){target="_blank"}

```{r embed-11, echo = FALSE}
embed_xaringan("slides/glm.html", ratio = "4:3")
```

:::

::: {.panel}

# Week 12

## Week Learning Objectives

By the end of this module, you will be able to 

- Draw a **directed acyclic graph (DAG)** to represent causal assumptions
- Use a DAG to guide analyses for obtaining **causal effects**
- Describe how **randomization** can remove potential **confounders**
- Explain how the **back-door criterion** can be used to identify a set of adjusted variables with nonexperimental data
- Perform a **mediation analysis** and interpret the results

## Task Lists

1. Complete the assigned readings
    * McElreath ch 5, 6
2. Review the resources ([note][20])
3. Attend class meetings
4. Complete Homework 8 (see instruction on Blackboard)

[20]: causal_inference.html

## Slides

[PDF version](slides/causal_inference.pdf){target="_blank"}

```{r embed-12, echo = FALSE}
embed_xaringan("slides/causal_inference.html", ratio = "4:3")
```

:::

:::

## Last updated {.appendix}

```{r, echo = FALSE}
format(Sys.Date(), "%B %d, %Y")
```
